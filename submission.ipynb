{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/ext3/conda/dlproj/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import imageio.v3 as iio\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torchmetrics\n",
    "import config\n",
    "import models as m\n",
    "import utils as u\n",
    "import gc\n",
    "from segmentation_models_pytorch.losses import JaccardLoss\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Copy hidden file into your scratch folder\n",
    "\n",
    "- download the file from https://drive.google.com/drive/folders/1geJERvh-wODANvEJlnh_nB2QPOwU-cAG locally\n",
    "- copy the file from local terminal to our project folder within your scratch directlory\n",
    "    `scp hidden_set_for_leaderboard_1.zip <your netid>@greene.hpc.nyu.edu:/scratch/<your netid>/video_prediction_project\n",
    "`\n",
    "- unzip the file \n",
    "    `unzip hidden_set_for_leaderboard_1.zip`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Configuration used for pretrain and finetune\n",
    "image_size=(160,240)\n",
    "patch_size=config.pretrain_config['patch_size']\n",
    "embed_dim=config.pretrain_config['embed_dim']\n",
    "expander_out=config.pretrain_config['expander_out']\n",
    "kernel_size=config.finetune_config['kernel_size']\n",
    "padding=config.finetune_config['padding']\n",
    "stride=config.finetune_config['stride']\n",
    "batch_size=config.finetune_config['batch_size']\n",
    "num_epochs=config.finetune_config['num_epochs']\n",
    "lr=config.finetune_config['lr']\n",
    "\n",
    "## Load the models  \n",
    "# use cpu\n",
    "device = \"cpu\"\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# we should also manually update pretrain path in case we do pretrain and finetune at the same time\n",
    "# the model_id for pretrain wouldn't have been updated in config\n",
    "VICReg_model_path = 'VICReg_pretrained_1682887688.pth'  #config.pretrain_config['model_id'] \n",
    "VICReg_model = m.VICReg(image_size, patch_size, embed_dim, expander_out=expander_out).to(device)\n",
    "VICReg_model.load_state_dict(torch.load(VICReg_model_path))\n",
    "VICReg_model.eval()\n",
    "print(f'loaded model {config.pretrain_config[\"model_id\"]}')\n",
    "\n",
    "# final_model_path = 'video_predictor_finetuned_1682558449.pth'\n",
    "final_model_path = 'video_predictor_finetuned_best_val_1682889093.pth' #Jaccard 0.0192\n",
    "# final_model_path = 'video_predictor_finetuned_best_val_1682895029.pth' #Jaccard 0.0192\n",
    "video_prediction_model = m.VideoPredictor(VICReg_model, kernel_size, padding, stride).to(device)\n",
    "video_prediction_model.load_state_dict(torch.load(final_model_path))\n",
    "video_prediction_model = video_prediction_model.to(device)\n",
    "video_prediction_model.eval()\n",
    "\n",
    "del VICReg_model\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "jaccard = torchmetrics.JaccardIndex(task=\"multiclass\", num_classes=49)\n",
    "criterion = JaccardLoss(mode='multiclass', classes=49) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Recompute Jaccard loss on train and validation set. \n",
    "train_folder=\"Dataset_Student/train/\"\n",
    "\n",
    "train_dataloader = u.create_finetune_dataloader(train_folder, image_size, batch_size= 1000, train_or_val='train')\n",
    "\n",
    "for i, data in enumerate(tqdm(train_dataloader)):\n",
    "    x_train, y_train = data\n",
    "    y_train_pred = video_prediction_model(x_train).argmax(dim=1) \n",
    "    del x_train\n",
    "    print(\"Optimized loss\", criterion(y_train_pred, y_train))\n",
    "    print(\"Jaccard Index loss:\", jaccard(y_train_pred, y_train))\n",
    "    del y_train_pred, y_train\n",
    "    \n",
    "del train_dataloader\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_folder=\"Dataset_Student/val/\"\n",
    "\n",
    "val_dataloader = u.create_finetune_dataloader(val_folder, image_size, batch_size= 1000, train_or_val='val')\n",
    "\n",
    "for i, data in enumerate(tqdm(val_dataloader)):\n",
    "    x_val, y_val = data\n",
    "    y_val_pred = video_prediction_model(x_val).argmax(dim=1) \n",
    "    del x_val\n",
    "    print(\"Optimized loss\", criterion(y_val_pred, y_val))\n",
    "    print(\"Jaccard Index loss:\", jaccard(y_val_pred, y_val))\n",
    "    del y_val_pred, y_val\n",
    "    \n",
    "del val_dataloader\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n"
     ]
    }
   ],
   "source": [
    "hidden_folder=\"hidden/\"\n",
    "num_hidden_videos = len( [hidden_folder + v for v in os.listdir(hidden_folder)])\n",
    "print(num_hidden_videos)\n",
    "hidden_dataloader = u.create_hidden_dataloader(hidden_folder, image_size, batch_size= num_hidden_videos, hidden_set='hidden')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_data = 0\n",
    "for data in hidden_dataloader:\n",
    "    len_data += data.size(0)\n",
    "print(len_data)\n",
    "\n",
    "output = torch.zeros(len_data, 160, 240)\n",
    "\n",
    "b_index = 0\n",
    "for data in tqdm(hidden_dataloader, desc='generating outputs'):\n",
    "    data = data.to(device)\n",
    "    y_pred = video_prediction_model(data)\n",
    "    y_pred = y_pred.argmax(dim=1)\n",
    "    output[b_index:b_index+batch_size] = y_pred\n",
    "    b_index += batch_size\n",
    "torch.save(output, 'submitted_tensor.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
