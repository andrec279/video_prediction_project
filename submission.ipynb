{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import imageio.v3 as iio\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torchmetrics\n",
    "import config\n",
    "import models as m\n",
    "import utils as u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded model VICReg_pretrained_1682484312.pth\n",
      "loading fake_hidden finetuning data from disk...\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "image_size=(160,240)\n",
    "patch_size=config.pretrain_config['patch_size']\n",
    "embed_dim=config.pretrain_config['embed_dim']\n",
    "expander_out=config.pretrain_config['expander_out']\n",
    "kernel_size=config.finetune_config['kernel_size']\n",
    "padding=config.finetune_config['padding']\n",
    "stride=config.finetune_config['stride']\n",
    "batch_size=config.finetune_config['batch_size']\n",
    "num_epochs=config.finetune_config['num_epochs']\n",
    "lr=config.finetune_config['lr']\n",
    "\n",
    "hidden_folder=\"Dataset_Student/val/\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "VICReg_model_path = config.pretrain_config['model_id']\n",
    "VICReg_model = m.VICReg(image_size, patch_size, embed_dim, expander_out=expander_out)\n",
    "VICReg_model.load_state_dict(torch.load(VICReg_model_path))\n",
    "VICReg_model.eval()\n",
    "print(f'loaded model {config.pretrain_config[\"model_id\"]}')\n",
    "\n",
    "final_model_path = 'video_predictor_finetuned_1682558449.pth'\n",
    "video_prediction_model = m.VideoPredictor(VICReg_model, kernel_size, padding, stride)\n",
    "video_prediction_model.load_state_dict(torch.load(final_model_path))\n",
    "video_prediction_model = video_prediction_model.to(device)\n",
    "video_prediction_model.eval()\n",
    "\n",
    "hidden_dataloader = u.create_finetune_dataloader(hidden_folder, image_size, batch_size, train_or_val='fake_hidden')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    }
   ],
   "source": [
    "len_data = 0\n",
    "for data in hidden_dataloader:\n",
    "    x, y = data\n",
    "    len_data += x.size(0)\n",
    "print(len_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "generating outputs: 100%|██████████| 63/63 [00:02<00:00, 21.78it/s]\n"
     ]
    }
   ],
   "source": [
    "len_data = 0\n",
    "for data in hidden_dataloader:\n",
    "    x, y = data\n",
    "    len_data += x.size(0)\n",
    "output = torch.zeros(len_data, 160, 240)\n",
    "\n",
    "b_index = 0\n",
    "for data in tqdm(hidden_dataloader, desc='generating outputs'):\n",
    "    x, y = data\n",
    "    x = x.to(device)\n",
    "    y = y.to(device)\n",
    "    y_pred = video_prediction_model(x)\n",
    "    y_pred = y_pred.argmax(dim=1)\n",
    "    output[b_index:b_index+batch_size] = y_pred\n",
    "    b_index += batch_size\n",
    "\n",
    "torch.save(output, 'submitted_tensor.pt')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
