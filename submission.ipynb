{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/ext3/conda/dlproj/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import imageio.v3 as iio\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torchmetrics\n",
    "import config\n",
    "import models as m\n",
    "import utils as u\n",
    "import gc\n",
    "from segmentation_models_pytorch.losses import JaccardLoss\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Copy hidden file into your scratch folder\n",
    "\n",
    "- download the file from https://drive.google.com/drive/folders/1geJERvh-wODANvEJlnh_nB2QPOwU-cAG locally\n",
    "- copy the file from local terminal to our project folder within your scratch directlory\n",
    "    `scp hidden_set_for_leaderboard_1.zip <your netid>@greene.hpc.nyu.edu:/scratch/<your netid>/video_prediction_project\n",
    "`\n",
    "- unzip the file \n",
    "    `unzip hidden_set_for_leaderboard_1.zip`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Configuration used for pretrain and finetune\n",
    "image_size=(160,240)\n",
    "patch_size=config.pretrain_config['patch_size']\n",
    "embed_dim=config.pretrain_config['embed_dim']\n",
    "expander_out=config.pretrain_config['expander_out']\n",
    "kernel_size= config.finetune_config['kernel_size']\n",
    "padding= config.finetune_config['padding']\n",
    "stride=config.finetune_config['stride']\n",
    "batch_size= config.finetune_config['batch_size']\n",
    "num_epochs=config.finetune_config['num_epochs']\n",
    "lr=config.finetune_config['lr']\n",
    "\n",
    "## Load the models  \n",
    "# use cpu\n",
    "device = \"cpu\"\n",
    "\n",
    "VICReg_model_path = 'VICReg_pretrained_1682959065.pth'\n",
    "VICReg_model = m.VICReg(image_size, patch_size, embed_dim, expander_out=expander_out).to(device)\n",
    "VICReg_model.load_state_dict(torch.load(VICReg_model_path))\n",
    "VICReg_model.eval()\n",
    "\n",
    "final_model_path = 'video_predictor_finetuned_best_val_1682959078.pth'\n",
    "video_prediction_model = m.VideoPredictor(VICReg_model, kernel_size, padding, stride).to(device)\n",
    "video_prediction_model.load_state_dict(torch.load(final_model_path))\n",
    "video_prediction_model = video_prediction_model.to(device)\n",
    "video_prediction_model.eval()\n",
    "\n",
    "del VICReg_model\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "jaccard = torchmetrics.JaccardIndex(task=\"multiclass\", num_classes=49)\n",
    "criterion = JaccardLoss(mode='multiclass', classes=49) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading train finetuning data from disk...\n",
      "done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jaccard Index loss: tensor(0.0193)\n",
      "Optimized loss tensor(0.9979, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:35<00:00, 35.71s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Recompute Jaccard loss on train and validation set. \n",
    "train_folder=\"Dataset_Student/train/\"\n",
    "num_train_videos = len( [train_folder + v for v in os.listdir(train_folder)])\n",
    "\n",
    "train_dataloader = u.create_finetune_dataloader(train_folder, image_size, batch_size= num_train_videos, train_or_val='train')\n",
    "\n",
    "for i, data in enumerate(tqdm(train_dataloader)):\n",
    "    x_train, y_train = data\n",
    "    y_train_pred = video_prediction_model(x_train)\n",
    "    del x_train\n",
    "    print(\"Jaccard Index loss:\", jaccard(y_train_pred.argmax(dim=1), y_train))\n",
    "    print(\"Optimized loss\", criterion(y_train_pred.log_softmax(dim=1).exp() , y_train))\n",
    "    del y_train_pred, y_train\n",
    "    \n",
    "del train_dataloader\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading val finetuning data from disk...\n",
      "done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jaccard Index loss: tensor(0.0193)\n",
      "Optimized loss tensor(0.9979, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:32<00:00, 32.13s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_folder=\"Dataset_Student/val/\"\n",
    "num_val_videos = len( [val_folder + v for v in os.listdir(val_folder)])\n",
    "\n",
    "val_dataloader = u.create_finetune_dataloader(val_folder, image_size, batch_size= num_val_videos, train_or_val='val')\n",
    "\n",
    "for i, data in enumerate(tqdm(val_dataloader)):\n",
    "    x_val, y_val = data\n",
    "    y_val_pred = video_prediction_model(x_val)\n",
    "    del x_val\n",
    "    print(\"Jaccard Index loss:\", jaccard(y_val_pred.argmax(dim=1) , y_val))\n",
    "    print(\"Optimized loss\", criterion(y_val_pred.log_softmax(dim=1).exp(), y_val))\n",
    "    del y_val_pred, y_val\n",
    "    \n",
    "del val_dataloader\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n",
      "loading hidden finetuning data from disk...\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "hidden_folder=\"hidden/\"\n",
    "batch_size = len( [hidden_folder + v for v in os.listdir(hidden_folder)])\n",
    "print(batch_size)\n",
    "hidden_dataloader = u.create_hidden_dataloader(hidden_folder, image_size, batch_size= batch_size, hidden_set='hidden')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "generating outputs: 100%|██████████| 1/1 [00:28<00:00, 28.21s/it]\n"
     ]
    }
   ],
   "source": [
    "len_data = 0\n",
    "for data in hidden_dataloader:\n",
    "    len_data += data.size(0)\n",
    "print(len_data)\n",
    "\n",
    "output = torch.zeros(len_data, 160, 240)\n",
    "\n",
    "b_index = 0\n",
    "for data in tqdm(hidden_dataloader, desc='generating outputs'):\n",
    "    data = data.to(device)\n",
    "    y_pred = video_prediction_model(data)\n",
    "    y_pred = y_pred.argmax(dim=1)\n",
    "    output[b_index:b_index+batch_size] = y_pred\n",
    "    b_index += batch_size\n",
    "torch.save(output, 'submitted_tensor_team12.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 15, 16, 17, 18,\n",
       "        19, 20, 21, 22, 23, 25, 26, 27, 28, 29, 31, 32, 33, 34, 35, 36, 37, 38,\n",
       "        39, 40, 42, 43, 44, 45, 46, 47, 48])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0000, 0.0039, 0.0078, 0.0118, 0.0157, 0.0196, 0.0235, 0.0275, 0.0314,\n",
       "        0.0353, 0.0392, 0.0431, 0.0471, 0.0510, 0.0549, 0.0588, 0.0627, 0.0667,\n",
       "        0.0706, 0.0745, 0.0784, 0.0824, 0.0863, 0.0902, 0.0941, 0.0980, 0.1020,\n",
       "        0.1059, 0.1098, 0.1137, 0.1176, 0.1216, 0.1255, 0.1294, 0.1333, 0.1373,\n",
       "        0.1412, 0.1451, 0.1490, 0.1529, 0.1569, 0.1608, 0.1647, 0.1686, 0.1725,\n",
       "        0.1765, 0.1804, 0.1843, 0.1882, 0.1922, 0.1961, 0.2000, 0.2039, 0.2078,\n",
       "        0.2118, 0.2157, 0.2196, 0.2235, 0.2275, 0.2314, 0.2353, 0.2392, 0.2431,\n",
       "        0.2471, 0.2510, 0.2549, 0.2588, 0.2627, 0.2667, 0.2706, 0.2745, 0.2784,\n",
       "        0.2824, 0.2863, 0.2902, 0.2941, 0.2980, 0.3020, 0.3059, 0.3098, 0.3137,\n",
       "        0.3176, 0.3216, 0.3255, 0.3294, 0.3333, 0.3373, 0.3412, 0.3451, 0.3490,\n",
       "        0.3529, 0.3569, 0.3608, 0.3647, 0.3686, 0.3725, 0.3765, 0.3804, 0.3843,\n",
       "        0.3882, 0.3922, 0.3961, 0.4000, 0.4039, 0.4078, 0.4118, 0.4157, 0.4196,\n",
       "        0.4235, 0.4275, 0.4314, 0.4353, 0.4392, 0.4431, 0.4471, 0.4510, 0.4549,\n",
       "        0.4588, 0.4627, 0.4667, 0.4706, 0.4745, 0.4784, 0.4824, 0.4863, 0.4902,\n",
       "        0.4941, 0.4980, 0.5020, 0.5059, 0.5098, 0.5137, 0.5176, 0.5216, 0.5255,\n",
       "        0.5294, 0.5333, 0.5373, 0.5412, 0.5451, 0.5490, 0.5529, 0.5569, 0.5608,\n",
       "        0.5647, 0.5686, 0.5725, 0.5765, 0.5804, 0.5843, 0.5882, 0.5922, 0.5961,\n",
       "        0.6000, 0.6039, 0.6078, 0.6118, 0.6157, 0.6196, 0.6235, 0.6275, 0.6314,\n",
       "        0.6353, 0.6392, 0.6431, 0.6471, 0.6510, 0.6549, 0.6588, 0.6627, 0.6667,\n",
       "        0.6706, 0.6745, 0.6784, 0.6824, 0.6863, 0.6902, 0.6941, 0.6980, 0.7020,\n",
       "        0.7059, 0.7098, 0.7137, 0.7176, 0.7216, 0.7255, 0.7294, 0.7333, 0.7373,\n",
       "        0.7412, 0.7451, 0.7490, 0.7529, 0.7569, 0.7608, 0.7647, 0.7686, 0.7725,\n",
       "        0.7765, 0.7804, 0.7843, 0.7882, 0.7922, 0.7961, 0.8000, 0.8039, 0.8078,\n",
       "        0.8118, 0.8157, 0.8196, 0.8235, 0.8275, 0.8314, 0.8353, 0.8392, 0.8431,\n",
       "        0.8471, 0.8510, 0.8549, 0.8588, 0.8627, 0.8667, 0.8706, 0.8745, 0.8784,\n",
       "        0.8824, 0.8863, 0.8902, 0.8941, 0.8980, 0.9020, 0.9059, 0.9098, 0.9137,\n",
       "        0.9176, 0.9216, 0.9255, 0.9294, 0.9333, 0.9373, 0.9412, 0.9451, 0.9490,\n",
       "        0.9529, 0.9569, 0.9608, 0.9647, 0.9686, 0.9725, 0.9765, 0.9804, 0.9843,\n",
       "        0.9882, 0.9922, 0.9961, 1.0000])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
